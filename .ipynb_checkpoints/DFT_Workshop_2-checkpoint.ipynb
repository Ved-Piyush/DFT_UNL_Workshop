{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Image credit [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f8d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc928b9d",
   "metadata": {},
   "source": [
    "# Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2835807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981c8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f0ede08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f5649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tfds.load(\n",
    "    'yelp_polarity_reviews',\n",
    "    split='train',\n",
    "    shuffle_files=True,\n",
    ")\n",
    "ds_train = tfds.as_dataframe(ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3f5960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'wow.  used to so much like the ones by us in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>b\"Went for dinner last night and was very impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Cheap food, every time I have gone they alwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b'The salesperson there was very gracious and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>b'When I decided to buy a scooter, I had no id...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  b'wow.  used to so much like the ones by us in...\n",
       "1      1  b\"Went for dinner last night and was very impr...\n",
       "2      0  b'Cheap food, every time I have gone they alwa...\n",
       "3      1  b'The salesperson there was very gracious and ...\n",
       "4      1  b'When I decided to buy a scooter, I had no id..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1676b003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c933aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much data to keep\n",
    "ds_train = ds_train.sample(frac = 0.75, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc4b52df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420000, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce8ee9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"First time: 5 stars\\\\n+ I seriously left dreaming about this place and couldn't wait to return\\\\n+ Really fresh fish\\\\n+ AYCE sushi that's affordable\\\\n+ AYCE includes desserts (I ordered 3 -  yes, I have a sweet tooth)\\\\n+ Special nigiri items can be ordered as well\\\\n- Long wait (but it was totally worth it)\\\\n- No sashimi\\\\n\\\\nSecond time: 4 stars\\\\n+ Wait wasn't as long\\\\n- Fish wasn't as fresh \\\\n\\\\nOverall would definitely return to this off-the-strip AYCE sushi joint.  It's such a good deal and the fresh is relatively fresh.  If you're not into sushi they have other options as well.  Till next time Goyemon!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.iloc[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f9c7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.iloc[0][\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5f58c4",
   "metadata": {},
   "source": [
    "### Step 1 - Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8118ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95d0e880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'time',\n",
       " 'stars',\n",
       " 'seriously',\n",
       " 'left',\n",
       " 'dreaming',\n",
       " 'about',\n",
       " 'this',\n",
       " 'place',\n",
       " 'and',\n",
       " 'couldn',\n",
       " 'wait',\n",
       " 'to',\n",
       " 'return',\n",
       " 'really',\n",
       " 'fresh',\n",
       " 'fish',\n",
       " 'ayce',\n",
       " 'sushi',\n",
       " 'that']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase\n",
    "# ignore too short and too long tokens\n",
    "utils.simple_preprocess(ds_train.iloc[0][\"text\"])[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f50a0cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5454c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9c4d4b3aab46588246fcbb84198ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/420000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize each review and store as list of words\n",
    "tokenized_reviews = []\n",
    "for text in tqdm(ds_train[\"text\"]): \n",
    "    tokenized_reviews.append(utils.simple_preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba7cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will detect bigrams\n",
    "from gensim.models import Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "228eaa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['first',\n",
       "  'time',\n",
       "  'stars',\n",
       "  'seriously',\n",
       "  'left',\n",
       "  'dreaming',\n",
       "  'about',\n",
       "  'this',\n",
       "  'place',\n",
       "  'and',\n",
       "  'couldn',\n",
       "  'wait',\n",
       "  'to',\n",
       "  'return',\n",
       "  'really',\n",
       "  'fresh',\n",
       "  'fish',\n",
       "  'ayce',\n",
       "  'sushi',\n",
       "  'that',\n",
       "  'affordable',\n",
       "  'ayce',\n",
       "  'includes',\n",
       "  'desserts',\n",
       "  'ordered',\n",
       "  'yes',\n",
       "  'have',\n",
       "  'sweet',\n",
       "  'tooth',\n",
       "  'special',\n",
       "  'nigiri',\n",
       "  'items',\n",
       "  'can',\n",
       "  'be',\n",
       "  'ordered',\n",
       "  'as',\n",
       "  'well',\n",
       "  'long',\n",
       "  'wait',\n",
       "  'but',\n",
       "  'it',\n",
       "  'was',\n",
       "  'totally',\n",
       "  'worth',\n",
       "  'it',\n",
       "  'no',\n",
       "  'sashimi',\n",
       "  'nsecond',\n",
       "  'time',\n",
       "  'stars',\n",
       "  'wait',\n",
       "  'wasn',\n",
       "  'as',\n",
       "  'long',\n",
       "  'fish',\n",
       "  'wasn',\n",
       "  'as',\n",
       "  'fresh',\n",
       "  'noverall',\n",
       "  'would',\n",
       "  'definitely',\n",
       "  'return',\n",
       "  'to',\n",
       "  'this',\n",
       "  'off',\n",
       "  'the',\n",
       "  'strip',\n",
       "  'ayce',\n",
       "  'sushi',\n",
       "  'joint',\n",
       "  'it',\n",
       "  'such',\n",
       "  'good',\n",
       "  'deal',\n",
       "  'and',\n",
       "  'the',\n",
       "  'fresh',\n",
       "  'is',\n",
       "  'relatively',\n",
       "  'fresh',\n",
       "  'if',\n",
       "  'you',\n",
       "  're',\n",
       "  'not',\n",
       "  'into',\n",
       "  'sushi',\n",
       "  'they',\n",
       "  'have',\n",
       "  'other',\n",
       "  'options',\n",
       "  'as',\n",
       "  'well',\n",
       "  'till',\n",
       "  'next',\n",
       "  'time',\n",
       "  'goyemon']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_reviews[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c90fe8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fir the gensim bigram model\n",
    "bigram = Phrases(tokenized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "177e7d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the list of tokenized reviews to the bigram model object\n",
    "bigram_tokenized_reviews = bigram[tokenized_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa79b241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'time',\n",
       " 'stars',\n",
       " 'seriously',\n",
       " 'left',\n",
       " 'dreaming_about',\n",
       " 'this',\n",
       " 'place',\n",
       " 'and',\n",
       " 'couldn',\n",
       " 'wait',\n",
       " 'to',\n",
       " 'return',\n",
       " 'really',\n",
       " 'fresh',\n",
       " 'fish',\n",
       " 'ayce_sushi',\n",
       " 'that',\n",
       " 'affordable',\n",
       " 'ayce',\n",
       " 'includes',\n",
       " 'desserts',\n",
       " 'ordered',\n",
       " 'yes',\n",
       " 'have',\n",
       " 'sweet_tooth',\n",
       " 'special',\n",
       " 'nigiri',\n",
       " 'items',\n",
       " 'can',\n",
       " 'be',\n",
       " 'ordered',\n",
       " 'as',\n",
       " 'well',\n",
       " 'long',\n",
       " 'wait',\n",
       " 'but',\n",
       " 'it',\n",
       " 'was',\n",
       " 'totally_worth',\n",
       " 'it',\n",
       " 'no',\n",
       " 'sashimi',\n",
       " 'nsecond',\n",
       " 'time',\n",
       " 'stars',\n",
       " 'wait',\n",
       " 'wasn',\n",
       " 'as',\n",
       " 'long',\n",
       " 'fish',\n",
       " 'wasn',\n",
       " 'as',\n",
       " 'fresh',\n",
       " 'noverall',\n",
       " 'would',\n",
       " 'definitely',\n",
       " 'return',\n",
       " 'to',\n",
       " 'this',\n",
       " 'off',\n",
       " 'the',\n",
       " 'strip',\n",
       " 'ayce_sushi',\n",
       " 'joint',\n",
       " 'it',\n",
       " 'such',\n",
       " 'good',\n",
       " 'deal',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fresh',\n",
       " 'is',\n",
       " 'relatively',\n",
       " 'fresh',\n",
       " 'if',\n",
       " 'you',\n",
       " 're',\n",
       " 'not',\n",
       " 'into',\n",
       " 'sushi',\n",
       " 'they',\n",
       " 'have',\n",
       " 'other',\n",
       " 'options',\n",
       " 'as',\n",
       " 'well',\n",
       " 'till',\n",
       " 'next',\n",
       " 'time',\n",
       " 'goyemon']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tokenized_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "676f53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram.save(\"bigram_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12e05266",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phrases.load(\"bigram_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c8bf44",
   "metadata": {},
   "source": [
    "# Train Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae8ffce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaebb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting the word2vec model\n",
    "# sg = 0 is for CBOW 1 for skip-gram\n",
    "# model = gensim.models.Word2Vec(sentences=bigram_tokenized_reviews, vector_size = 100, \n",
    "#                               window = 5, min_count = 5, max_vocab_size = None, sg = 0, workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model so you dont have to train again\n",
    "# model.save(\"yelp_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b5c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = gensim.models.Word2Vec.load(\"yelp_word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19251bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89073"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many words\n",
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "891aa290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5954207 ,  0.9215558 ,  0.5002837 , -1.0792872 ,  0.15311298,\n",
       "        0.38278088,  1.1268    ,  0.5279211 ,  0.5314047 , -0.5242518 ,\n",
       "       -0.63606566,  0.65701336, -0.665191  ,  0.1737934 ,  0.17205867,\n",
       "        0.50990766, -0.73550326,  1.5150176 , -1.3236736 , -0.9226875 ,\n",
       "        0.815984  ,  0.17829499, -1.3470298 ,  1.3521905 ,  1.5117137 ,\n",
       "        1.0000699 ,  1.5407293 , -0.18895806, -1.1945325 , -1.7376685 ,\n",
       "       -2.8940902 ,  0.11137597,  1.0917991 , -2.7263606 ,  0.02620541,\n",
       "        1.5034566 ,  1.2069572 , -0.26808172, -0.72729355,  0.92445034,\n",
       "       -0.6396061 , -0.03437746, -1.7500983 , -0.60100937, -0.0658905 ,\n",
       "       -0.6145809 ,  0.2629476 , -1.104312  , -0.945986  , -0.03267215,\n",
       "       -1.6544546 ,  0.5292398 ,  0.4113373 ,  0.6807149 ,  3.0900521 ,\n",
       "        0.48221853,  2.9971917 ,  1.7336515 ,  2.395294  ,  1.1309831 ,\n",
       "        0.39629656, -0.2856317 ,  1.6745335 , -1.0451968 , -2.7337499 ,\n",
       "        2.686315  , -1.8451014 ,  2.4041522 , -2.5629377 ,  0.8163977 ,\n",
       "        2.5398226 ,  1.136912  , -0.21606806,  1.3751153 ,  0.25756678,\n",
       "       -1.050144  , -0.2701767 , -3.292505  , -1.1069927 , -2.5584664 ,\n",
       "       -0.92486334, -0.6701193 , -1.9352764 ,  0.51697445,  0.36421654,\n",
       "        0.8374509 ,  3.2954924 , -0.71661204,  0.11393601, -0.6701702 ,\n",
       "       -0.63533044, -0.33881256,  1.8210751 , -0.8810679 , -0.35925528,\n",
       "       -0.6426484 ,  0.08676749,  1.0062894 ,  0.86280876,  0.18826108],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a particular word vector using the word itself\n",
    "model.wv.get_vector(\"mcdonalds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f2651d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mcdonald', 0.9432393908500671),\n",
       " ('burger_king', 0.9023249745368958),\n",
       " ('mcd', 0.8458371758460999),\n",
       " ('denny', 0.8444104194641113),\n",
       " ('subway', 0.8436354994773865),\n",
       " ('taco_bell', 0.8319615721702576),\n",
       " ('wendy', 0.8295611143112183),\n",
       " ('dennys', 0.8171852827072144),\n",
       " ('waffle_house', 0.809360921382904),\n",
       " ('panda_express', 0.8076522946357727)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check most similar words\n",
    "model.wv.most_similar('mcdonalds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d449b088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89073, 100)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final word embedding matrix\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86daa694",
   "metadata": {},
   "source": [
    "# Can we visualize Word Vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7055b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sims = model.wv.most_similar('mcdonalds', topn=model.wv.vectors.shape[0])\n",
    "top_10 = list(all_sims[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501d4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63ec2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_sims = model.wv.most_similar('mcdonalds', topn=model.wv.vectors.shape[0])\n",
    "not_top_10 = list(all_sims[190:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2adcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c42eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_vectors = []\n",
    "for word in top_10:\n",
    "    cur_word = word[0]\n",
    "    cur_word_vec =  model.wv.get_vector(cur_word)\n",
    "    top_10_vectors.append(cur_word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90052eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_vectors = np.array(top_10_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9b22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_top_10_vectors = []\n",
    "for word in not_top_10:\n",
    "    cur_word = word[0]\n",
    "    cur_word_vec =  model.wv.get_vector(cur_word)\n",
    "    not_top_10_vectors.append(cur_word_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_top_10_vectors = np.array(not_top_10_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_vectors_df = pd.DataFrame(top_10_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db8377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_vectors_df[\"word\"] = [item[0] for item in top_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7feeed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_top_10_vectors_df = pd.DataFrame(not_top_10_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3945ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_top_10_vectors_df[\"word\"] = [item[0] for item in not_top_10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03c448",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_not_top_10 = pd.concat([top_10_vectors_df, not_top_10_vectors_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb8806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6140cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(top_not_top_10.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_vectors = pca.transform(top_not_top_10.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5eb578",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_vectors_df = pd.concat([pd.DataFrame(projected_vectors), pd.DataFrame(top_not_top_10[\"word\"])],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d79530",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_vectors_df.columns = [\"x\", \"y\", \"z\", \"word\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_vectors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af661b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter_3d(projected_vectors_df, x=\"x\", y=\"y\", z=\"z\",\n",
    "              text='word')\n",
    "fig.write_html(\"word_cloud_yelp_reviews.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the word to numeric index mapping\n",
    "model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36ae9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the word vectors for index 0 is the same if you use indexing or name\n",
    "\n",
    "# using indexing\n",
    "model.wv.vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8840e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.wv.key_to_index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8a5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm the word vectors for index 0 is the same\n",
    "# using name\n",
    "model.wv.get_vector(list(model.wv.key_to_index)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1255e",
   "metadata": {},
   "source": [
    "# Is Word2Vec Smart?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f6ee1",
   "metadata": {},
   "source": [
    "### Vector Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a9ac50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference for the analogies [5]\n",
    "\n",
    "## these analogies might not work if you reduce the data too much\n",
    "\n",
    "## in that case some of the words below might not have been in the training corpus\n",
    "## and therefore we wouldnt have any word vectors for them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd57ef55",
   "metadata": {},
   "source": [
    "#### breakfast + lunch = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[\"breakfast\", \"lunch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed296a4a",
   "metadata": {},
   "source": [
    "#### lunch - day + night = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3105617",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[u'lunch', u'night'], negative=[u'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658cbeec",
   "metadata": {},
   "source": [
    "#### coffee - drink + snack = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa827b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[u'coffee', u'snack'], negative=[u'drink'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d660f4b",
   "metadata": {},
   "source": [
    "#### Burger King + fine dining = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[u'burger_king', u'fine_dining'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c223cb6",
   "metadata": {},
   "source": [
    "#### Denny's + fine dining = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9554b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[u'dennys', u'fine_dining'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc67b12",
   "metadata": {},
   "source": [
    "#### Applebee's + italian = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f466b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[u\"applebee\", u'italian'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061b40e",
   "metadata": {},
   "source": [
    "#### Applebee's + pancakes = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d8fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[u\"applebee\", u'pancakes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d08684",
   "metadata": {},
   "source": [
    "#### Applebee's + pizza = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c9ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar(positive=[u\"applebee\", u'pizza'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "## most similar is only one of the utility functions\n",
    "## but gensim offers many different utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f0b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"breakfast\", \"lunch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c43f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(\"breakfast\", \"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.doesnt_match([\"breakfast\", \"car\", \"lunch\", \"dinner\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32fb44",
   "metadata": {},
   "source": [
    "# What if we get some new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d4a1557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a new sample of data\n",
    "ds_test = tfds.load(\n",
    "    'yelp_polarity_reviews',\n",
    "    split='test',\n",
    "    shuffle_files=True,\n",
    ")\n",
    "ds_test = tfds.as_dataframe(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c000dc51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38000, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ac5e274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>b'Was not impressed, and will not return.'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>b'I went in to purchase overalls and was treat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>b'This place really is horrible... Every time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>b'First time visit.....  enjoyed their little ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b'I\\'ll start with the good -  Price, Location...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0         b'Was not impressed, and will not return.'\n",
       "1      0  b'I went in to purchase overalls and was treat...\n",
       "2      0  b'This place really is horrible... Every time ...\n",
       "3      1  b'First time visit.....  enjoyed their little ...\n",
       "4      0  b'I\\'ll start with the good -  Price, Location..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51cf162d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a70457ed28a424baad8da165df6f3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize each review and store as list of words\n",
    "tokenized_test_reviews = []\n",
    "for text in tqdm(ds_test[\"text\"]): \n",
    "    tokenized_test_reviews.append(utils.simple_preprocess(text))\n",
    "\n",
    "\n",
    "# pass the list of tokenized reviews to the bigram model object\n",
    "bigram_tokenized_test_reviews = bigram[tokenized_test_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f30729cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17169765, 22901205)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ update the word2vec model with the test data as well? \n",
    "model.build_vocab(bigram_tokenized_test_reviews, update=True)\n",
    "model.train(bigram_tokenized_test_reviews, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bda93b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89170"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed4798f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89170, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final word embedding matrix\n",
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a182df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model so you dont have to train again\n",
    "model.save(\"yelp_word2vec_updated_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5289e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = gensim.models.Word2Vec.load(\"yelp_word2vec_updated_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e073e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b5d9f",
   "metadata": {},
   "source": [
    "# Using Word2Vec for Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8722f52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to average the word vectors\n",
    "# ignores the words that are not in the vocab\n",
    "def average_word_vectors(idx):\n",
    "    text = bigram_tokenized_test_reviews[idx]\n",
    "    word_vectors = []\n",
    "    for word in text: \n",
    "        if len(vocab.intersection([word])) == 1:\n",
    "            word_vectors.append(model.wv.get_vector(word))\n",
    "    \n",
    "    if len(word_vectors) > 0:\n",
    "        return np.array(word_vectors).mean(0)\n",
    "    \n",
    "    else:\n",
    "        return(np.zeros((1, model.wv.vectors.shape[1])))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5b170be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514ddca98a13458d9c03ca34aac34232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use the abive function and store in a list\n",
    "average_word_vectors_test = np.zeros((ds_test.shape[0], model.wv.vectors.shape[1]))\n",
    "counter = 0\n",
    "for i in  tqdm(range(ds_test.shape[0])):\n",
    "    average_word_vectors_test[counter,:] = average_word_vectors(i)\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "554fb1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0c9b014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\AppData\\Local\\Temp\\ipykernel_15112\\2055854068.py:2: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  test_data_with_average_vectors = pd.concat([pd.DataFrame(average_word_vectors_test), ds_test[\"label\"]],1)\n"
     ]
    }
   ],
   "source": [
    "# convert to a dataframe\n",
    "test_data_with_average_vectors = pd.concat([pd.DataFrame(average_word_vectors_test), ds_test[\"label\"]],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21077a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.424024</td>\n",
       "      <td>-0.700056</td>\n",
       "      <td>0.097169</td>\n",
       "      <td>0.674064</td>\n",
       "      <td>0.527084</td>\n",
       "      <td>0.598445</td>\n",
       "      <td>1.202447</td>\n",
       "      <td>-0.257022</td>\n",
       "      <td>0.130901</td>\n",
       "      <td>0.215007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851286</td>\n",
       "      <td>-0.990031</td>\n",
       "      <td>-0.121236</td>\n",
       "      <td>0.194301</td>\n",
       "      <td>-0.631200</td>\n",
       "      <td>-0.251535</td>\n",
       "      <td>0.629992</td>\n",
       "      <td>0.226676</td>\n",
       "      <td>-0.343596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.206348</td>\n",
       "      <td>-0.315422</td>\n",
       "      <td>0.428004</td>\n",
       "      <td>-0.369890</td>\n",
       "      <td>-0.950479</td>\n",
       "      <td>0.258945</td>\n",
       "      <td>0.689689</td>\n",
       "      <td>-0.332470</td>\n",
       "      <td>0.364710</td>\n",
       "      <td>0.304101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772579</td>\n",
       "      <td>-0.985501</td>\n",
       "      <td>-0.914002</td>\n",
       "      <td>-0.458235</td>\n",
       "      <td>-0.302389</td>\n",
       "      <td>-0.637496</td>\n",
       "      <td>0.138051</td>\n",
       "      <td>0.265036</td>\n",
       "      <td>-0.097515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023439</td>\n",
       "      <td>0.170056</td>\n",
       "      <td>-0.174807</td>\n",
       "      <td>-0.183004</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>0.381339</td>\n",
       "      <td>0.068949</td>\n",
       "      <td>0.152840</td>\n",
       "      <td>0.173853</td>\n",
       "      <td>-0.070727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145002</td>\n",
       "      <td>0.406710</td>\n",
       "      <td>-0.495650</td>\n",
       "      <td>-0.089761</td>\n",
       "      <td>0.307980</td>\n",
       "      <td>0.157156</td>\n",
       "      <td>0.397281</td>\n",
       "      <td>0.349354</td>\n",
       "      <td>-0.363138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.193409</td>\n",
       "      <td>0.103001</td>\n",
       "      <td>-0.529377</td>\n",
       "      <td>0.278799</td>\n",
       "      <td>-0.232966</td>\n",
       "      <td>-0.209779</td>\n",
       "      <td>-0.482386</td>\n",
       "      <td>-0.122429</td>\n",
       "      <td>0.195486</td>\n",
       "      <td>0.237129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041765</td>\n",
       "      <td>-0.069597</td>\n",
       "      <td>0.607927</td>\n",
       "      <td>0.489913</td>\n",
       "      <td>0.857186</td>\n",
       "      <td>-0.490995</td>\n",
       "      <td>0.034571</td>\n",
       "      <td>-0.342732</td>\n",
       "      <td>-0.365460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.252760</td>\n",
       "      <td>0.036868</td>\n",
       "      <td>-0.016586</td>\n",
       "      <td>0.287304</td>\n",
       "      <td>-0.672313</td>\n",
       "      <td>-0.076965</td>\n",
       "      <td>-0.037880</td>\n",
       "      <td>0.347945</td>\n",
       "      <td>0.015328</td>\n",
       "      <td>-0.583083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037533</td>\n",
       "      <td>-0.410264</td>\n",
       "      <td>-0.253524</td>\n",
       "      <td>-0.143890</td>\n",
       "      <td>0.072430</td>\n",
       "      <td>-0.443154</td>\n",
       "      <td>0.348752</td>\n",
       "      <td>0.319020</td>\n",
       "      <td>-0.476614</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.424024 -0.700056  0.097169  0.674064  0.527084  0.598445  1.202447   \n",
       "1  0.206348 -0.315422  0.428004 -0.369890 -0.950479  0.258945  0.689689   \n",
       "2  0.023439  0.170056 -0.174807 -0.183004 -0.139097  0.381339  0.068949   \n",
       "3 -0.193409  0.103001 -0.529377  0.278799 -0.232966 -0.209779 -0.482386   \n",
       "4  0.252760  0.036868 -0.016586  0.287304 -0.672313 -0.076965 -0.037880   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0 -0.257022  0.130901  0.215007  ...  0.851286 -0.990031 -0.121236  0.194301   \n",
       "1 -0.332470  0.364710  0.304101  ...  0.772579 -0.985501 -0.914002 -0.458235   \n",
       "2  0.152840  0.173853 -0.070727  ...  0.145002  0.406710 -0.495650 -0.089761   \n",
       "3 -0.122429  0.195486  0.237129  ... -0.041765 -0.069597  0.607927  0.489913   \n",
       "4  0.347945  0.015328 -0.583083  ... -0.037533 -0.410264 -0.253524 -0.143890   \n",
       "\n",
       "         95        96        97        98        99  label  \n",
       "0 -0.631200 -0.251535  0.629992  0.226676 -0.343596      0  \n",
       "1 -0.302389 -0.637496  0.138051  0.265036 -0.097515      0  \n",
       "2  0.307980  0.157156  0.397281  0.349354 -0.363138      0  \n",
       "3  0.857186 -0.490995  0.034571 -0.342732 -0.365460      1  \n",
       "4  0.072430 -0.443154  0.348752  0.319020 -0.476614      0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_with_average_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56412dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the na row\n",
    "test_data_with_average_vectors = test_data_with_average_vectors.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e58ab130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "87ee6a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e2d78d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f0d3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the parameters here as a dictionary\n",
    "param_grid = {\"n_estimators\": [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7085d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the grid search object\n",
    "gs = GridSearchCV(rf, param_grid, cv = 5, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0910569d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ..................n_estimators=100;, score=0.866 total time=  11.5s\n",
      "[CV 2/5] END ..................n_estimators=100;, score=0.872 total time=   6.6s\n",
      "[CV 3/5] END ..................n_estimators=100;, score=0.869 total time=   6.5s\n",
      "[CV 4/5] END ..................n_estimators=100;, score=0.873 total time=   6.7s\n",
      "[CV 5/5] END ..................n_estimators=100;, score=0.868 total time=   6.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=6),\n",
       "             param_grid={&#x27;n_estimators&#x27;: [100]}, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=6),\n",
       "             param_grid={&#x27;n_estimators&#x27;: [100]}, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=6)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=6)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=6),\n",
       "             param_grid={'n_estimators': [100]}, verbose=3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the gridsearch object\n",
    "gs.fit(test_data_with_average_vectors.iloc[:,:-1], test_data_with_average_vectors.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9bea1f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8697368421052631"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 fold averaged score\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80e0e9",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e01f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countvectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cffe8ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline to put different steps together\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c7c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa100c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vec = CountVectorizer(min_df=15, lowercase=True, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc333c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vec.fit(ds_test[\"text\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05961cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_count_vec = count_vec.transform(ds_test[\"text\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8aaf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_count_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_labels = ds_test[\"label\"].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7534d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_count_vec = text_count_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48bd8110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21fd5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first step count vectorize\n",
    "# next step classification\n",
    "pipeline_bow = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer(min_df=5, lowercase=True, ngram_range=(1,2))),\n",
    "#         (\"transform\",FunctionTransformer(lambda x: x.todense(), accept_sparse=True)),\n",
    "        (\"clf\", LogisticRegression(penalty = \"elasticnet\", solver  =\"saga\")),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "106aebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the parameters by writing the name you used for the steps and then \"__\"\n",
    "param_grid_bow = {\"clf__l1_ratio\": [0.5], \n",
    "                 \"vect__max_features\": [100, 500, 1000, 2000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fe131f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the grid search object\n",
    "lr_bow_gs = GridSearchCV(pipeline_bow, param_grid_bow, cv = 5, verbose = 3, error_score='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac673b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END clf__l1_ratio=0.5, vect__max_features=100;, score=0.761 total time=  13.6s\n",
      "[CV 2/5] END clf__l1_ratio=0.5, vect__max_features=100;, score=0.770 total time=  14.2s\n",
      "[CV 3/5] END clf__l1_ratio=0.5, vect__max_features=100;, score=0.760 total time=  13.1s\n",
      "[CV 4/5] END clf__l1_ratio=0.5, vect__max_features=100;, score=0.769 total time=  13.8s\n",
      "[CV 5/5] END clf__l1_ratio=0.5, vect__max_features=100;, score=0.774 total time=  12.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__l1_ratio=0.5, vect__max_features=500;, score=0.868 total time=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__l1_ratio=0.5, vect__max_features=500;, score=0.866 total time=  20.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__l1_ratio=0.5, vect__max_features=500;, score=0.858 total time=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__l1_ratio=0.5, vect__max_features=500;, score=0.868 total time=  19.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__l1_ratio=0.5, vect__max_features=500;, score=0.868 total time=  20.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__l1_ratio=0.5, vect__max_features=1000;, score=0.889 total time=  26.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__l1_ratio=0.5, vect__max_features=1000;, score=0.889 total time=  26.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__l1_ratio=0.5, vect__max_features=1000;, score=0.892 total time=  29.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__l1_ratio=0.5, vect__max_features=1000;, score=0.894 total time=  26.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__l1_ratio=0.5, vect__max_features=1000;, score=0.891 total time=  26.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END clf__l1_ratio=0.5, vect__max_features=2000;, score=0.905 total time=  37.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END clf__l1_ratio=0.5, vect__max_features=2000;, score=0.909 total time=  38.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END clf__l1_ratio=0.5, vect__max_features=2000;, score=0.908 total time=  38.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END clf__l1_ratio=0.5, vect__max_features=2000;, score=0.911 total time=  38.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END clf__l1_ratio=0.5, vect__max_features=2000;, score=0.912 total time=  38.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\.conda\\envs\\newone1\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        CountVectorizer(min_df=5,\n",
       "                                                        ngram_range=(1, 2))),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(penalty=&#x27;elasticnet&#x27;,\n",
       "                                                           solver=&#x27;saga&#x27;))]),\n",
       "             param_grid={&#x27;clf__l1_ratio&#x27;: [0.5],\n",
       "                         &#x27;vect__max_features&#x27;: [100, 500, 1000, 2000]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, error_score=&#x27;raise&#x27;,\n",
       "             estimator=Pipeline(steps=[(&#x27;vect&#x27;,\n",
       "                                        CountVectorizer(min_df=5,\n",
       "                                                        ngram_range=(1, 2))),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(penalty=&#x27;elasticnet&#x27;,\n",
       "                                                           solver=&#x27;saga&#x27;))]),\n",
       "             param_grid={&#x27;clf__l1_ratio&#x27;: [0.5],\n",
       "                         &#x27;vect__max_features&#x27;: [100, 500, 1000, 2000]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer(min_df=5, ngram_range=(1, 2))),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LogisticRegression(penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(min_df=5, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;elasticnet&#x27;, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(min_df=5,\n",
       "                                                        ngram_range=(1, 2))),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(penalty='elasticnet',\n",
       "                                                           solver='saga'))]),\n",
       "             param_grid={'clf__l1_ratio': [0.5],\n",
       "                         'vect__max_features': [100, 500, 1000, 2000]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit by directly passing the text data\n",
    "lr_bow_gs.fit(ds_test[\"text\"].astype(str), ds_test[\"label\"].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29a3819f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9091052631578946"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 fold averaged score\n",
    "lr_bow_gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb09b0a5",
   "metadata": {},
   "source": [
    "#### Doc2Vec Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2912671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "34aea13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first',\n",
       " 'time',\n",
       " 'stars',\n",
       " 'seriously',\n",
       " 'left',\n",
       " 'dreaming_about',\n",
       " 'this',\n",
       " 'place',\n",
       " 'and',\n",
       " 'couldn',\n",
       " 'wait',\n",
       " 'to',\n",
       " 'return',\n",
       " 'really',\n",
       " 'fresh',\n",
       " 'fish',\n",
       " 'ayce_sushi',\n",
       " 'that',\n",
       " 'affordable',\n",
       " 'ayce',\n",
       " 'includes',\n",
       " 'desserts',\n",
       " 'ordered',\n",
       " 'yes',\n",
       " 'have',\n",
       " 'sweet_tooth',\n",
       " 'special',\n",
       " 'nigiri',\n",
       " 'items',\n",
       " 'can',\n",
       " 'be',\n",
       " 'ordered',\n",
       " 'as',\n",
       " 'well',\n",
       " 'long',\n",
       " 'wait',\n",
       " 'but',\n",
       " 'it',\n",
       " 'was',\n",
       " 'totally_worth',\n",
       " 'it',\n",
       " 'no',\n",
       " 'sashimi',\n",
       " 'nsecond',\n",
       " 'time',\n",
       " 'stars',\n",
       " 'wait',\n",
       " 'wasn',\n",
       " 'as',\n",
       " 'long',\n",
       " 'fish',\n",
       " 'wasn',\n",
       " 'as',\n",
       " 'fresh',\n",
       " 'noverall',\n",
       " 'would',\n",
       " 'definitely',\n",
       " 'return',\n",
       " 'to',\n",
       " 'this',\n",
       " 'off',\n",
       " 'the',\n",
       " 'strip',\n",
       " 'ayce_sushi',\n",
       " 'joint',\n",
       " 'it',\n",
       " 'such',\n",
       " 'good',\n",
       " 'deal',\n",
       " 'and',\n",
       " 'the',\n",
       " 'fresh',\n",
       " 'is',\n",
       " 'relatively',\n",
       " 'fresh',\n",
       " 'if',\n",
       " 'you',\n",
       " 're',\n",
       " 'not',\n",
       " 'into',\n",
       " 'sushi',\n",
       " 'they',\n",
       " 'have',\n",
       " 'other',\n",
       " 'options',\n",
       " 'as',\n",
       " 'well',\n",
       " 'till',\n",
       " 'next',\n",
       " 'time',\n",
       " 'goyemon']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tokenized_reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "de43590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(bigram_tokenized_reviews)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a230fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dm = 0 (wont train word vectors unless dbow_words = 1) \n",
    "## is for PV-DBOW and dm = 1 for PV-DM (this will also train wordvectors and will be slower)\n",
    "\n",
    "## PV DM trains word vecs and doc vecs jointly so they will be in the same latent space\n",
    "\n",
    "## you can also combine dbow docvec training with skip-gram word2vec training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b32c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is dbow training with no word vectors training\n",
    "model_doc2vec = Doc2Vec(documents, vector_size=100, window=5, min_count=5, \n",
    "                max_vocab_size = None, dm = 0, dbow_words = 0, workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b48792",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc2vec.dv.vectors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f6123",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc2vec.wv.vectors.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b828226",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc2vec.save(\"doc2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "188cca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doc2vec = Doc2Vec.load(\"doc2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1485c0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e04b0e914c84c39b371e86e00bd0e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_vectors_test = np.zeros((ds_test.shape[0], model_doc2vec.dv.vectors.shape[1]))\n",
    "counter = 0\n",
    "for i in  tqdm(range(ds_test.shape[0])):\n",
    "    doc_vectors_test[counter,:] = model_doc2vec.infer_vector(bigram_tokenized_test_reviews[i])\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "abb00571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12740333, -0.04252623, -0.12010309, -0.15111555, -0.02159969,\n",
       "       -0.0466487 , -0.05456675, -0.10682402, -0.16092806, -0.00024953,\n",
       "       -0.1980863 ,  0.00542467,  0.06942987, -0.00358879, -0.01333259,\n",
       "        0.08755029,  0.11056387,  0.1593351 ,  0.09521074,  0.16908862,\n",
       "       -0.10223883,  0.07661804, -0.00250234, -0.04443074,  0.02750483,\n",
       "        0.02344697,  0.1514215 , -0.12096574, -0.08844744, -0.05042389,\n",
       "       -0.04914619, -0.0687502 , -0.0707244 ,  0.03824665,  0.07084145,\n",
       "       -0.07525028,  0.11513499,  0.02423349, -0.09514002,  0.00283078,\n",
       "        0.05316712,  0.11461578,  0.0645297 , -0.05068608,  0.04649041,\n",
       "       -0.06147944, -0.01180126, -0.00935863,  0.02278047,  0.08635486,\n",
       "       -0.11586186, -0.02865634,  0.02269515, -0.08487106, -0.04284452,\n",
       "        0.06117215,  0.07111584, -0.14696641, -0.224923  ,  0.02988753,\n",
       "        0.08003271,  0.03400295,  0.05538803,  0.02615677,  0.11765283,\n",
       "       -0.07268206, -0.03791004,  0.00281054,  0.01295131,  0.03840444,\n",
       "        0.12248966, -0.07487362,  0.06271122,  0.09143174,  0.0995288 ,\n",
       "        0.08248025, -0.08575017, -0.09615038, -0.056874  , -0.1369469 ,\n",
       "        0.02196123,  0.1315497 ,  0.06639232,  0.15888384, -0.05307139,\n",
       "        0.06568609, -0.12587047,  0.05979316,  0.09877895, -0.02063689,\n",
       "       -0.07502413, -0.0644485 ,  0.00108418,  0.01963143, -0.04258954,\n",
       "       -0.01158036, -0.082215  ,  0.11032084, -0.17422253, -0.04672056],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc2vec.infer_vector([\"breakfast\", \"lunch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "919e0277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedpi\\AppData\\Local\\Temp\\ipykernel_15112\\3753805467.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  test_data_with_doc_vectors = pd.concat([pd.DataFrame(doc_vectors_test), ds_test[\"label\"]],1)\n"
     ]
    }
   ],
   "source": [
    "test_data_with_doc_vectors = pd.concat([pd.DataFrame(doc_vectors_test), ds_test[\"label\"]],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9be2dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.010963</td>\n",
       "      <td>0.024556</td>\n",
       "      <td>0.033487</td>\n",
       "      <td>-0.030405</td>\n",
       "      <td>-0.010700</td>\n",
       "      <td>0.160846</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>0.045562</td>\n",
       "      <td>-0.308516</td>\n",
       "      <td>-0.129442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046861</td>\n",
       "      <td>0.050250</td>\n",
       "      <td>-0.028404</td>\n",
       "      <td>0.047572</td>\n",
       "      <td>-0.109506</td>\n",
       "      <td>-0.010114</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>-0.121606</td>\n",
       "      <td>0.043996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.067657</td>\n",
       "      <td>0.215513</td>\n",
       "      <td>0.113546</td>\n",
       "      <td>-0.178188</td>\n",
       "      <td>0.046497</td>\n",
       "      <td>0.033798</td>\n",
       "      <td>0.153311</td>\n",
       "      <td>-0.057600</td>\n",
       "      <td>-0.494990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023305</td>\n",
       "      <td>0.085243</td>\n",
       "      <td>-0.196187</td>\n",
       "      <td>-0.002344</td>\n",
       "      <td>-0.035031</td>\n",
       "      <td>-0.239109</td>\n",
       "      <td>0.044488</td>\n",
       "      <td>-0.386034</td>\n",
       "      <td>-0.026507</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060576</td>\n",
       "      <td>-0.321535</td>\n",
       "      <td>0.124541</td>\n",
       "      <td>-0.589404</td>\n",
       "      <td>0.117055</td>\n",
       "      <td>-0.210162</td>\n",
       "      <td>-0.243618</td>\n",
       "      <td>0.080497</td>\n",
       "      <td>-0.386968</td>\n",
       "      <td>-0.189406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145396</td>\n",
       "      <td>-0.087417</td>\n",
       "      <td>-0.061523</td>\n",
       "      <td>0.195065</td>\n",
       "      <td>0.138643</td>\n",
       "      <td>-0.055118</td>\n",
       "      <td>0.164058</td>\n",
       "      <td>-0.636384</td>\n",
       "      <td>-0.225305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.127900</td>\n",
       "      <td>0.011965</td>\n",
       "      <td>-0.151027</td>\n",
       "      <td>-0.070436</td>\n",
       "      <td>0.431418</td>\n",
       "      <td>-0.276977</td>\n",
       "      <td>0.003214</td>\n",
       "      <td>-0.389544</td>\n",
       "      <td>-0.206026</td>\n",
       "      <td>-0.029095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198486</td>\n",
       "      <td>0.024890</td>\n",
       "      <td>0.259501</td>\n",
       "      <td>0.250445</td>\n",
       "      <td>0.182513</td>\n",
       "      <td>0.194714</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>-0.252609</td>\n",
       "      <td>-0.014311</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.302764</td>\n",
       "      <td>0.530054</td>\n",
       "      <td>-0.029385</td>\n",
       "      <td>-0.454152</td>\n",
       "      <td>-0.136055</td>\n",
       "      <td>-0.090069</td>\n",
       "      <td>0.083840</td>\n",
       "      <td>-0.095688</td>\n",
       "      <td>0.072761</td>\n",
       "      <td>0.540542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>-0.173468</td>\n",
       "      <td>-0.195882</td>\n",
       "      <td>0.298731</td>\n",
       "      <td>-0.521504</td>\n",
       "      <td>-0.015584</td>\n",
       "      <td>1.108533</td>\n",
       "      <td>-0.179358</td>\n",
       "      <td>-0.375045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.010963  0.024556  0.033487 -0.030405 -0.010700  0.160846  0.061600   \n",
       "1  0.002518  0.067657  0.215513  0.113546 -0.178188  0.046497  0.033798   \n",
       "2  0.060576 -0.321535  0.124541 -0.589404  0.117055 -0.210162 -0.243618   \n",
       "3 -0.127900  0.011965 -0.151027 -0.070436  0.431418 -0.276977  0.003214   \n",
       "4  0.302764  0.530054 -0.029385 -0.454152 -0.136055 -0.090069  0.083840   \n",
       "\n",
       "          7         8         9  ...        91        92        93        94  \\\n",
       "0  0.045562 -0.308516 -0.129442  ...  0.046861  0.050250 -0.028404  0.047572   \n",
       "1  0.153311 -0.057600 -0.494990  ...  0.023305  0.085243 -0.196187 -0.002344   \n",
       "2  0.080497 -0.386968 -0.189406  ...  0.145396 -0.087417 -0.061523  0.195065   \n",
       "3 -0.389544 -0.206026 -0.029095  ...  0.198486  0.024890  0.259501  0.250445   \n",
       "4 -0.095688  0.072761  0.540542  ...  0.363625 -0.173468 -0.195882  0.298731   \n",
       "\n",
       "         95        96        97        98        99  label  \n",
       "0 -0.109506 -0.010114  0.040207 -0.121606  0.043996      0  \n",
       "1 -0.035031 -0.239109  0.044488 -0.386034 -0.026507      0  \n",
       "2  0.138643 -0.055118  0.164058 -0.636384 -0.225305      0  \n",
       "3  0.182513  0.194714  0.020806 -0.252609 -0.014311      1  \n",
       "4 -0.521504 -0.015584  1.108533 -0.179358 -0.375045      0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_with_doc_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f5ceba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1405f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_estimators\": [100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86cb6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_doc2vec = GridSearchCV(rf, param_grid, cv = 5, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91dea951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV 1/5] END ..................n_estimators=100;, score=0.877 total time=   9.9s\n",
      "[CV 2/5] END ..................n_estimators=100;, score=0.869 total time=   6.3s\n",
      "[CV 3/5] END ..................n_estimators=100;, score=0.875 total time=   6.5s\n",
      "[CV 4/5] END ..................n_estimators=100;, score=0.874 total time=   6.4s\n",
      "[CV 5/5] END ..................n_estimators=100;, score=0.874 total time=   6.4s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=6),\n",
       "             param_grid={&#x27;n_estimators&#x27;: [100]}, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=6),\n",
       "             param_grid={&#x27;n_estimators&#x27;: [100]}, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=6)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=6)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(n_jobs=6),\n",
       "             param_grid={'n_estimators': [100]}, verbose=3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_doc2vec.fit(test_data_with_doc_vectors.iloc[:,:-1], test_data_with_doc_vectors.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea8fd5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873578947368421"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_doc2vec.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f80203",
   "metadata": {},
   "source": [
    "### References for images used\n",
    "\n",
    "[1] https://openclassrooms.com/en/courses/6532301-introduction-to-natural-language-processing/6980811-apply-a-simple-bag-of-words-approach\n",
    "\n",
    "[2] https://swatimeena989.medium.com/training-word2vec-using-gensim-14433890e8e4\n",
    "\n",
    "[3] http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\n",
    "\n",
    "[4] https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e\n",
    "\n",
    "[5] https://github.com/pwharrison/modern-nlp-in-python/blob/master/executable/Modern_NLP_in_Python.ipynb\n",
    "\n",
    "[6] https://stackoverflow.com/questions/67697776/how-did-online-training-work-in-the-word2vec-model-using-genism\n",
    "\n",
    "[7] https://stackoverflow.com/questions/53616003/doc2vec-online-training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newone1",
   "language": "python",
   "name": "newone1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
